{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Tokenization**"
      ],
      "metadata": {
        "id": "SWDwXXENbELv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "#nltk.download('all')\n",
        "from nltk import word_tokenize,sent_tokenize\n",
        "sent=input(\"Enter the sentence for tokenization and Stopword \")\n",
        "print(word_tokenize(sent)) #word tokenization\n",
        "print(sent_tokenize(sent)) #sentence tokenization\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-kFr-k8bKiu",
        "outputId": "4ff7a99a-6e13-4f8e-bfcf-0d772dca5539"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the sentence for tokenization and Stopword this is an example sentence with stopwords.hi my name is Chinmay.\n",
            "['this', 'is', 'an', 'example', 'sentence', 'with', 'stopwords.hi', 'my', 'name', 'is', 'Chinmay', '.']\n",
            "['this is an example sentence with stopwords.hi my name is Chinmay.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Character Tokenization**"
      ],
      "metadata": {
        "id": "ooS2dfklnob4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def char_tokenize(sent):\n",
        "  return [char for char in sent if char!=' ']\n",
        "\n",
        "print(char_tokenize(sent))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYAqiNHQnnh6",
        "outputId": "a35f12e4-a085-4e3e-e45a-c37b064eb1d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['T', 'h', 'i', 's', 'i', 's', 'a', 'n', 'e', 'x', 'a', 'm', 'p', 'l', 'e', 's', 'e', 'n', 't', 'e', 'n', 'c', 'e', 'w', 'i', 't', 'h', 's', 't', 'o', 'p', 'w', 'o', 'r', 'd', 's', '.', 'H', 'i', 'm', 'y', 'n', 'a', 'm', 'e', 'i', 's', 'C', 'h', 'i', 'n', 'm', 'a', 'y', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Stop Word**"
      ],
      "metadata": {
        "id": "v3W6f_QVfHVg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "stopwords=set(stopwords.words('english'))\n",
        "print(stopwords)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jiWfFdbfPpn",
        "outputId": "d2c4350c-9b77-45db-db9b-399f004be95c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"mustn't\", 'by', \"wouldn't\", 'there', 'and', 'it', 'into', \"that'll\", 'did', 'before', 'yours', 'd', 'ain', 'its', 'won', 'shan', 'has', 'all', 'any', 'again', 'now', 'why', 'each', 's', \"you'll\", 'weren', 'doing', 'with', 'between', 'his', 'on', \"hadn't\", 'against', 'y', 'll', 'for', 'them', 'we', \"you're\", 'have', 'same', 'mustn', 'then', \"didn't\", 'only', 'he', 'further', 'from', 'out', 'an', 'haven', 'who', 'ourselves', \"weren't\", 'wouldn', 'other', 'ma', 'couldn', \"aren't\", 'up', 'own', \"wasn't\", 'o', 'our', 'don', 'himself', \"mightn't\", 'not', 'once', 'me', \"you've\", 'nor', 'after', 'to', 'she', 'you', 'theirs', 'yourselves', 'their', 'about', 'needn', 'so', \"should've\", \"won't\", 'some', 'down', 'when', \"it's\", 'hers', 'whom', 'these', 'which', 'the', 'i', 'most', 'had', 'be', \"shouldn't\", 'were', 'wasn', 'hasn', 'just', 'been', 'this', \"she's\", 'should', 'over', 'shouldn', 're', 'being', 'above', \"couldn't\", 'of', 'while', 'more', \"needn't\", \"isn't\", 'because', 'where', 'can', 'ours', 'under', 'will', 'too', 'hadn', 'than', 'if', 'my', 'such', 't', 'at', 'him', 'what', \"haven't\", 'herself', 'those', 'doesn', 'that', 'do', 'off', 'during', 'very', \"you'd\", \"don't\", 'does', 'or', 'am', \"shan't\", 'here', 'aren', 'are', 'in', 'both', 'a', 've', \"doesn't\", 'how', 'your', 'having', 'no', 'her', \"hasn't\", 'itself', 'themselves', 'is', 'as', 'yourself', 'mightn', 'until', 'm', 'but', 'through', 'isn', 'didn', 'was', 'myself', 'few', 'they', 'below'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_stop_words(sent):\n",
        "  words=sent.split()\n",
        "  filtered_words=[word for word in words if word not in stopwords]\n",
        "  return ' '.join(filtered_words)\n",
        "\n",
        "filtered_sent=remove_stop_words(sent)\n",
        "print(sent)\n",
        "print(filtered_sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQX7snfriwm6",
        "outputId": "3831b02e-b930-4284-9c7b-2dede2888943"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this is an example sentence with stopwords.hi my name is Chinmay.\n",
            "example sentence stopwords.hi name Chinmay.\n"
          ]
        }
      ]
    }
  ]
}